{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "if os.path.abspath('../src') not in sys.path:\n",
    "    sys.path.append(os.path.abspath('../src'))\n",
    "# os.environ[\"PYTHONPATH\"] = '/opt/venv/lib/python3.11/site-packages'\n",
    "\n",
    "import logging\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import time\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Literal\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysmiles\n",
    "import torch\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.heterograph import DGLGraph\n",
    "from easydict import EasyDict\n",
    "from multiprocess import set_start_method\n",
    "from rdkit import Chem\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "from data_processing import mol_to_dgl, networkx_to_dgl\n",
    "from model import GNN\n",
    "\n",
    "try:\n",
    "    set_start_method(\"spawn\")\n",
    "except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "logging.getLogger('pysmiles').setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading hyperparameters of pretrained model from ../saved/tag_1024/hparams.pkl\n"
     ]
    }
   ],
   "source": [
    "args = EasyDict({'pretrained_model': 'tag_1024', 'gpu': 0})\n",
    "\n",
    "# load model parameters\n",
    "cache_path = '../saved/' + args.pretrained_model + '/'\n",
    "print('loading hyperparameters of pretrained model from ' + cache_path + 'hparams.pkl')\n",
    "with open(cache_path + 'hparams.pkl', 'rb') as f:\n",
    "    hparams = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from path ../saved/tag_1024\n"
     ]
    }
   ],
   "source": [
    "PRETRAINED_MODEL = 'tag_1024'\n",
    "\n",
    "# load model parameters\n",
    "cache_path = Path('../saved/' + PRETRAINED_MODEL)\n",
    "print('loading model from path ' + str(cache_path))\n",
    "\n",
    "hparams = pickle.load(cache_path.joinpath('hparams.pkl').open('rb'))\n",
    "feature_encoder = pickle.load(cache_path.joinpath('feature_enc.pkl').open('rb'))\n",
    "embedder = GNN(hparams['gnn'], hparams['layer'], hparams['feature_len'], hparams['dim'])\n",
    "if torch.cuda.is_available():\n",
    "    embedder.load_state_dict(torch.load(cache_path.joinpath('model.pt'), map_location=torch.device('cpu'), weights_only=True))\n",
    "    embedder = embedder.to('cuda:' + str(args.gpu))\n",
    "else:\n",
    "    embedder.load_state_dict(torch.load(cache_path.joinpath('model.pt'), map_location=torch.device('cpu'), weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_nx(example: dict[str, Any]) -> dict[str, Any]:\n",
    "    example['raw_graph'] = pysmiles.read_smiles(example['smiles'], zero_order_bonds=False)\n",
    "    return example\n",
    "\n",
    "def smiles_to_dgl(smiles: str, feature_encoder: dict[str, Any]) -> DGLGraph:\n",
    "    raw_graph = pysmiles.read_smiles(smiles, zero_order_bonds=False)\n",
    "    graph = networkx_to_dgl(raw_graph, feature_encoder)\n",
    "    return graph\n",
    "\n",
    "def smiles_to_dgl_gpu(smiles: str, feature_encoder: dict[str, Any], device: torch.device) -> DGLGraph:\n",
    "    raw_graph = pysmiles.read_smiles(smiles, zero_order_bonds=False)\n",
    "    graph = networkx_to_dgl(raw_graph, feature_encoder)\n",
    "    return graph.to(device)\n",
    "\n",
    "def smiles_to_dgl_rdkit(smiles: str, feature_encoder: dict[str, Any]) -> DGLGraph:\n",
    "    mol = Chem.RemoveHs(Chem.MolFromSmiles(smiles))\n",
    "    graph = mol_to_dgl(mol, feature_encoder)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmilesEmbedder:\n",
    "    def __init__(\n",
    "        self, \n",
    "        feature_encoder: dict[str, Any],\n",
    "        embedder: torch.nn.Module,\n",
    "        num_proc: int = 4,\n",
    "        processing_func: Literal['single', 'batch', 'batch_mp', 'rdkit'] = 'single'):\n",
    "\n",
    "        self.feature_encoder = feature_encoder\n",
    "        self.embedder = embedder\n",
    "        self.embedder.eval()\n",
    "        self.pool = multiprocessing.Pool(processes=num_proc)\n",
    "        if processing_func == 'single':\n",
    "            self.processing_function = self.process_one\n",
    "        elif processing_func == 'batch':\n",
    "            self.processing_function = self.process_batch\n",
    "        elif processing_func == 'batch_mp':\n",
    "            self.processing_function = self.process_batch_mp\n",
    "        elif processing_func == 'rdkit':\n",
    "            self.processing_function = self.process_batch_rdkit\n",
    "\n",
    "    def process_one(self, example: dict[str, Any], rank: int=0):\n",
    "        \"\"\"Transforms SMILES into an embedding\"\"\"\n",
    "        device = next(self.embedder.parameters()).device\n",
    "        raw_graph = pysmiles.read_smiles(example['smiles'], zero_order_bonds=False)\n",
    "        graph = networkx_to_dgl(raw_graph, self.feature_encoder)\n",
    "        graph = graph.to(device)\n",
    "        with torch.no_grad():\n",
    "            example['embedding'] = self.embedder(graph)\n",
    "        return example\n",
    "\n",
    "    def process_batch_mp(self, batch: dict[str, Any], rank: int=0):\n",
    "        \"\"\"Transforms SMILES into an embedding\"\"\"\n",
    "        device = next(self.embedder.parameters()).device\n",
    "        graphs = self.pool.map(\n",
    "                partial(\n",
    "                    self.smiles_to_dgl,\n",
    "                    feature_encoder=self.feature_encoder),\n",
    "                batch['smiles'])\n",
    "        with torch.no_grad():\n",
    "             batch['embedding'] = self.embedder(dgl.batch(graphs).to(device))\n",
    "        return batch\n",
    "\n",
    "    def process_batch(self, batch: dict[str, Any], rank: int=0):\n",
    "        \"\"\"Transforms SMILES into an embedding\"\"\"\n",
    "        device = next(self.embedder.parameters()).device\n",
    "        graphs = [self.smiles_to_dgl(smiles, feature_encoder=self.feature_encoder) for smiles in batch['smiles']]\n",
    "        graphs_gpu = [graph.to(device) for graph in graphs]\n",
    "        with torch.no_grad():\n",
    "             batch['embedding'] = self.embedder(dgl.batch(graphs_gpu))\n",
    "        return batch\n",
    "\n",
    "    def process_batch_rdkit(self, batch: dict[str, Any], rank: int=0):\n",
    "        \"\"\"Transforms SMILES into an embedding\"\"\"\n",
    "        device = next(self.embedder.parameters()).device\n",
    "        graphs = [self.smiles_to_dgl_rdkit(smiles, feature_encoder=self.feature_encoder) for smiles in batch['smiles']]\n",
    "        graphs_gpu = [graph.to(device) for graph in graphs]\n",
    "        with torch.no_grad():\n",
    "             batch['embedding'] = self.embedder(dgl.batch(graphs_gpu))\n",
    "        return batch\n",
    "\n",
    "    @staticmethod\n",
    "    def smiles_to_dgl(smiles: str, feature_encoder: dict[str, Any]) -> DGLGraph:\n",
    "        raw_graph = pysmiles.read_smiles(smiles, zero_order_bonds=False)\n",
    "        graph = networkx_to_dgl(raw_graph, feature_encoder)\n",
    "        return graph\n",
    "\n",
    "    @staticmethod\n",
    "    def smiles_to_dgl_rdkit(smiles: str, feature_encoder: dict[str, Any]) -> DGLGraph:\n",
    "        mol = Chem.RemoveHs(Chem.MolFromSmiles(smiles))\n",
    "        graph = mol_to_dgl(mol, feature_encoder)\n",
    "        return graph    \n",
    "\n",
    "    def __call__(self, smiles: str, rank: int=0) -> Any:\n",
    "        return self.processing_function(smiles, rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing speed test for different embedder variants with hf.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\"train\": [\"../../data/CS2/train.csv\"], \"test\": [\"../../data/CS2/test.csv\"]}\n",
    "dataset = load_dataset(\"csv\", data_files=data_files, split=\"train\").select(range(10000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<__main__.SmilesEmbedder object at 0x7f9463f0f790> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map: 100%|██████████| 10000/10000 [01:08<00:00, 145.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# embs = dataset.map(SmilesEmbedderGPU(feature_encoder=feature_encoder, embedder=mole))\n",
    "embs = dataset.map(\n",
    "    SmilesEmbedder(feature_encoder=feature_encoder, embedder=embedder, processing_func='single'),\n",
    "    #batched=True,\n",
    "    batch_size=512,\n",
    "    with_rank=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:30<00:00, 330.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "embs = dataset.map(\n",
    "    SmilesEmbedder(feature_encoder=feature_encoder, embedder=embedder, processing_func='batch'),\n",
    "    batched=True,\n",
    "    batch_size=512,\n",
    "    with_rank=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  31%|███       | 3072/10000 [00:11<00:23, 291.23 examples/s]"
     ]
    }
   ],
   "source": [
    "embs = dataset.map(\n",
    "    SmilesEmbedder(feature_encoder=feature_encoder, embedder=embedder, processing_func='batch_mp'),\n",
    "    batched=True,\n",
    "    batch_size=512,\n",
    "    with_rank=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = dataset.map(\n",
    "    SmilesEmbedder(feature_encoder=feature_encoder, embedder=embedder, processing_func='rdkit'),\n",
    "    batched=True,\n",
    "    batch_size=512,\n",
    "    with_rank=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Estimate for 1B dataset: {1000000000 / 350 / 60 / 60 / 24} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using native DGL data class - no better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmilesInMemoryDataset(dgl.data.DGLDataset):\n",
    "    def __init__(self, smiles_csv: str, feature_encoder: dict[str, Any], cache_path: str='./graphs.bin', gpu: int=0):\n",
    "        self.feature_encoder = feature_encoder\n",
    "        self.smiles_data = load_dataset(\"csv\", data_files={'train': [smiles_csv]}, split=\"train\").select(range(10000))\n",
    "        self.cache_path = cache_path\n",
    "        self.gpu = gpu\n",
    "        self.graphs = []\n",
    "        super().__init__(name='Smiles_data')\n",
    "\n",
    "    def to_gpu(self):\n",
    "        if torch.cuda.is_available():\n",
    "            print('moving data to GPU')\n",
    "            self.graphs = [graph.to('cuda:' + str(self.gpu)) for graph in self.graphs]\n",
    "\n",
    "    def save(self):\n",
    "        print('saving data to ' + self.cache_path)\n",
    "        dgl.save_graphs(self.cache_path, self.graphs)\n",
    "\n",
    "    def load(self):\n",
    "        print('loading graphs from ' + self.cache_path)\n",
    "        # graphs loaded from disk will have a default empty label set: [graphs, labels], so we only take the first item\n",
    "        self.graphs = dgl.load_graphs(self.cache_path)[0]\n",
    "        self.to_gpu()\n",
    "\n",
    "    def process(self):\n",
    "        print('transforming data from networkx graphs to DGL graphs')\n",
    "        for data in tqdm(self.smiles_data):\n",
    "            # transform networkx graphs to dgl graphs\n",
    "            graph = smiles_to_dgl(data['smiles'], self.feature_encoder)\n",
    "            self.graphs.append(graph)\n",
    "        self.to_gpu()\n",
    "\n",
    "    def has_cache(self):\n",
    "        return os.path.exists(self.cache_path)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('./graphs.bin')\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "dataset = SmilesInMemoryDataset(\n",
    "    smiles_csv=\"../../data/CS2/train.csv\",\n",
    "    feature_encoder=feature_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show that data loading is a bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_vs_batch_size(data, model, batch_sizes: list[int] = [1024]) -> pd.DataFrame:\n",
    "    model.eval()\n",
    "    mean_times = []\n",
    "    for batch_size in tqdm(batch_sizes, leave=False, desc=\"batch\"):\n",
    "        dataloader = GraphDataLoader(data, batch_size=batch_size)\n",
    "        with torch.no_grad():\n",
    "            times = []\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            for graphs_batch, _ in tqdm(dataloader):\n",
    "                start_time = time.time()\n",
    "                _ = model(graphs_batch)\n",
    "                end_time = time.time()\n",
    "                times.append(end_time - start_time)\n",
    "            mean_time = np.mean(times)\n",
    "        mean_times.append(mean_time)\n",
    "    return pd.DataFrame({'time': mean_times, 'batch_size': batch_sizes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = time_vs_batch_size(dataset, embedder, batch_sizes = [128, 256, 512, 1024, 2048, 4096])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
